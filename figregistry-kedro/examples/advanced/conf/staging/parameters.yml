# Staging Environment Parameters Configuration
# Advanced FigRegistry-Kedro Example - Production-like Validation Environment
#
# This configuration provides enterprise-grade experimental conditions and validation
# scenarios for comprehensive staging deployment testing. It mirrors production
# complexity while maintaining staging-specific safety measures and rollback capabilities.
#
# Purpose: Enable thorough condition-based styling testing, FigureDataSet validation,
# and production readiness validation through realistic experimental contexts.

# ==============================================================================
# STAGING DEPLOYMENT VALIDATION PARAMETERS
# ==============================================================================
# Production-like parameters supporting comprehensive staging validation per 
# Section 8.3.2.1 deployment strategy requirements

deployment:
  environment: "staging"
  validation_level: "enterprise"
  rollback_enabled: true
  safety_checks_enabled: true
  production_mirroring: true

# ==============================================================================
# EXPERIMENTAL CONDITION PARAMETERS  
# ==============================================================================
# Enterprise-grade experimental scenarios for comprehensive condition-based
# styling validation per F-002 requirements

# Primary experimental conditions for FigRegistry condition_param resolution
experiment_condition: "staging_enterprise_validation"
experimental_context: "production_readiness_testing"
validation_scenario: "comprehensive_enterprise_staging"

# Complex experimental parameter hierarchy for staging validation
experimental_conditions:
  # Primary staging validation scenarios
  primary:
    condition: "staging_enterprise_ml_pipeline"
    context: "production_like_training"
    complexity_level: "enterprise"
    validation_tier: "comprehensive"
    
  # Secondary validation scenarios for comprehensive testing
  secondary:
    condition: "staging_inference_validation"
    context: "production_like_inference"
    complexity_level: "production_grade"
    validation_tier: "extensive"
    
  # Fallback scenarios for error handling validation
  fallback:
    condition: "staging_error_recovery"
    context: "degraded_performance_testing"
    complexity_level: "minimal_safe"
    validation_tier: "basic"

# Advanced experimental parameter sets for production-like complexity
experimental_parameters:
  # Machine learning model complexity parameters
  model_complexity:
    feature_dimensions: 2048  # Production-like complexity
    hidden_layers: [512, 256, 128, 64]  # Enterprise-grade architecture
    dropout_rates: [0.3, 0.4, 0.2, 0.1]  # Production training parameters
    batch_sizes: [64, 128, 256]  # Staging-appropriate batch sizes
    learning_rates: [0.001, 0.0005, 0.0001]  # Production-grade schedules
    
  # Data processing complexity for staging validation
  data_complexity:
    dataset_size_multiplier: 0.7  # 70% of production size for staging
    feature_engineering_stages: 5  # Production-like preprocessing
    validation_splits: [0.7, 0.15, 0.15]  # Train/val/test production split
    cross_validation_folds: 5  # Enterprise validation standards
    
  # Pipeline execution complexity parameters
  pipeline_complexity:
    parallel_workers: 4  # Staging-appropriate parallelism
    memory_limit_gb: 16  # Production-like memory constraints
    timeout_minutes: 45  # Enterprise timeout limits
    retry_attempts: 3  # Production resilience standards

# ==============================================================================
# FIGREGISTRY INTEGRATION PARAMETERS
# ==============================================================================
# Production-appropriate condition_param resolution testing per F-005-RQ-004

# Primary figure generation parameters for FigureDataSet validation
figure_generation:
  # Training pipeline figure parameters
  training_figures:
    condition_param: "experimental_conditions.primary.condition"
    purpose: "presentation"  # Enterprise presentation quality
    validation_context: "training_performance"
    complexity_level: "production_grade"
    
  # Inference pipeline figure parameters  
  inference_figures:
    condition_param: "experimental_conditions.secondary.condition"
    purpose: "publication"  # Publication-ready staging outputs
    validation_context: "inference_validation"
    complexity_level: "enterprise"
    
  # Reporting pipeline figure parameters
  reporting_figures:
    condition_param: "validation_scenario"
    purpose: "presentation"
    validation_context: "comprehensive_reporting"
    complexity_level: "production_ready"

# Advanced styling parameters for comprehensive plugin validation
styling_parameters:
  # Enterprise color schemes for production-like validation
  color_schemes:
    primary: ["#1f77b4", "#ff7f0e", "#2ca02c", "#d62728", "#9467bd"]
    secondary: ["#8c564b", "#e377c2", "#7f7f7f", "#bcbd22", "#17becf"]
    staging_validation: ["#393b79", "#5254a3", "#6b6ecf", "#9c9ede", "#637939"]
    
  # Production-grade figure dimensions for staging validation
  figure_dimensions:
    standard: [12, 8]  # Enterprise-standard figure size
    large: [16, 12]    # Large presentation figures
    publication: [10, 7]  # Publication-ready dimensions
    
  # Enterprise DPI settings for production-like quality
  dpi_settings:
    preview: 150    # Staging preview quality
    standard: 300   # Production standard
    publication: 600  # Publication quality for staging validation

# ==============================================================================
# TRAINING PIPELINE PARAMETERS
# ==============================================================================
# Enterprise-grade model complexity parameters for comprehensive production 
# workflow testing per Section 8.3.2.1 deployment validation

training:
  # Advanced model architecture for production-like complexity
  model_architecture:
    input_features: 2048
    hidden_layers:
      layer_1: 512
      layer_2: 256  
      layer_3: 128
      layer_4: 64
    output_classes: 10
    activation: "relu"
    output_activation: "softmax"
    
  # Production-grade training parameters
  training_parameters:
    epochs: 50  # Reduced from production for staging efficiency
    batch_size: 128
    learning_rate: 0.001
    optimizer: "adam"
    loss_function: "categorical_crossentropy"
    metrics: ["accuracy", "precision", "recall", "f1_score"]
    
  # Enterprise validation and monitoring
  validation_config:
    validation_split: 0.2
    early_stopping_patience: 10
    reduce_lr_patience: 5
    model_checkpoint_period: 5
    tensorboard_logging: true
    
  # Staging-specific safety parameters
  staging_safety:
    max_training_time_minutes: 60
    memory_monitoring_enabled: true
    resource_limit_enforcement: true
    automatic_cleanup: true

# ==============================================================================
# INFERENCE PIPELINE PARAMETERS  
# ==============================================================================
# Production-like inference complexity for comprehensive staging validation

inference:
  # Enterprise inference configuration
  inference_config:
    batch_size: 256  # Production-like batch processing
    confidence_threshold: 0.85
    uncertainty_estimation: true
    ensemble_models: 3  # Multi-model inference validation
    
  # Production-grade performance monitoring
  performance_monitoring:
    latency_targets:
      p50_ms: 100
      p95_ms: 500
      p99_ms: 1000
    throughput_targets:
      requests_per_second: 100
      concurrent_requests: 20
    
  # Data validation parameters for staging
  data_validation:
    input_schema_validation: true
    outlier_detection_enabled: true
    drift_detection_threshold: 0.1
    quality_score_minimum: 0.9
    
  # Staging-specific inference safety
  staging_inference_safety:
    shadow_mode_enabled: true  # Run alongside production for comparison
    fallback_model_enabled: true
    result_validation_enabled: true
    anomaly_detection_enabled: true

# ==============================================================================
# REPORTING PIPELINE PARAMETERS
# ==============================================================================
# Comprehensive reporting parameters for staging deployment validation

reporting:
  # Enterprise reporting configuration
  report_generation:
    formats: ["pdf", "html", "png"]
    quality_level: "presentation"
    include_interactive_plots: true
    comprehensive_metrics: true
    
  # Production-like dashboard parameters
  dashboard_config:
    refresh_interval_minutes: 15
    data_retention_days: 30
    alert_thresholds:
      error_rate: 0.05
      latency_p95_ms: 1000
      accuracy_drop: 0.02
      
  # Staging validation reporting
  validation_reporting:
    performance_comparison_enabled: true
    production_baseline_comparison: true
    regression_testing_results: true
    capacity_planning_metrics: true

# ==============================================================================
# DATA PROCESSING PARAMETERS
# ==============================================================================
# Enterprise data processing complexity for staging validation

data_processing:
  # Production-scale data parameters (reduced for staging efficiency)
  data_scale:
    training_samples: 100000  # 70% of production scale
    validation_samples: 20000
    test_samples: 15000
    feature_dimensions: 2048
    
  # Enterprise feature engineering parameters
  feature_engineering:
    normalization_method: "robust_scaler"
    encoding_strategies: ["one_hot", "target", "binary"]
    feature_selection_k: 500
    dimensionality_reduction: "pca"
    variance_threshold: 0.01
    
  # Production-like preprocessing pipeline
  preprocessing:
    missing_value_strategy: "advanced_imputation"
    outlier_handling: "isolation_forest"
    data_validation_rules: "comprehensive"
    quality_checks_enabled: true

# ==============================================================================
# VALIDATION AND TESTING PARAMETERS
# ==============================================================================
# Comprehensive validation scenarios for enterprise staging deployment

validation:
  # Staging validation scenarios
  validation_scenarios:
    # Basic functionality validation
    basic_validation:
      hook_registration_test: true
      dataset_instantiation_test: true
      config_merge_validation: true
      
    # Advanced integration validation  
    integration_validation:
      end_to_end_pipeline_test: true
      multi_node_execution_test: true
      parallel_runner_test: true
      versioning_compatibility_test: true
      
    # Production readiness validation
    production_readiness:
      performance_benchmark_test: true
      resource_usage_validation: true
      error_handling_validation: true
      rollback_procedure_test: true
      
  # Performance validation thresholds
  performance_thresholds:
    max_dataset_save_overhead_percent: 5
    max_style_resolution_ms: 1
    max_config_merge_ms: 10
    max_hook_execution_ms: 50
    
  # Enterprise compliance validation
  compliance_validation:
    security_scan_enabled: true
    dependency_vulnerability_check: true
    code_quality_standards: "enterprise"
    documentation_completeness_check: true

# ==============================================================================
# MONITORING AND OBSERVABILITY
# ==============================================================================
# Enterprise monitoring parameters for staging deployment validation

monitoring:
  # Application performance monitoring
  apm_config:
    metrics_collection_enabled: true
    distributed_tracing_enabled: true
    error_tracking_enabled: true
    performance_profiling_enabled: true
    
  # Infrastructure monitoring
  infrastructure_monitoring:
    resource_usage_tracking: true
    memory_leak_detection: true
    cpu_usage_monitoring: true
    disk_io_monitoring: true
    
  # Business metrics monitoring
  business_metrics:
    pipeline_success_rate_tracking: true
    figure_generation_metrics: true
    styling_performance_metrics: true
    user_experience_metrics: true

# ==============================================================================
# ENVIRONMENT-SPECIFIC OVERRIDES
# ==============================================================================
# Staging-specific parameter overrides supporting comprehensive testing and
# production migration validation scenarios

environment_overrides:
  # Staging safety overrides
  safety_overrides:
    enable_debug_logging: true
    extensive_validation_enabled: true
    performance_monitoring_verbose: true
    automatic_rollback_on_failure: true
    
  # Resource limit overrides for staging
  resource_overrides:
    max_memory_usage_gb: 16
    max_cpu_cores: 8
    max_execution_time_minutes: 90
    max_file_size_mb: 100
    
  # Production migration preparation overrides
  migration_preparation:
    production_compatibility_mode: true
    schema_validation_strict: true
    performance_regression_detection: true
    backward_compatibility_testing: true

# ==============================================================================
# PLUGIN VALIDATION PARAMETERS
# ==============================================================================
# Specific parameters for comprehensive figregistry-kedro plugin validation

plugin_validation:
  # FigureDataSet validation parameters
  figure_dataset_validation:
    test_purposes: ["exploratory", "presentation", "publication"]
    test_conditions: 
      - "staging_enterprise_validation"
      - "staging_inference_validation" 
      - "staging_error_recovery"
    style_param_combinations: 10
    concurrent_save_operations: 5
    
  # Hook validation parameters
  hook_validation:
    registration_retry_attempts: 3
    context_injection_validation: true
    lifecycle_event_validation: true
    error_handling_validation: true
    
  # Configuration bridge validation
  config_bridge_validation:
    merge_scenario_testing: true
    precedence_rule_validation: true
    environment_override_testing: true
    validation_error_simulation: true